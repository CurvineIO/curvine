---
# Start Curvine cluster services
# Usage: ansible-playbook start_services.yml

- name: Check and Fix Environment Variables Before Start
  hosts: all
  gather_facts: yes
  any_errors_fatal: false
  ignore_unreachable: yes
  tasks:
    - name: Get current CURVINE_MASTER_HOSTNAME value
      shell: grep 'CURVINE_MASTER_HOSTNAME' /etc/profile | grep -v '^#' | tail -1 | sed 's/.*CURVINE_MASTER_HOSTNAME=//'
      register: current_hostname
      ignore_errors: yes
      changed_when: false

    - name: Get node IP for master nodes
      set_fact:
        node_ip: "{{ ansible_eth0.ipv4.address if ansible_eth0 is defined else (ansible_bond0.ipv4.address if ansible_bond0 is defined else ansible_default_ipv4.address) }}"
      when: "'master' in group_names"

    - name: Check and fix master node environment
      block:
        - name: Display current status
          debug:
            msg: |
              Master node {{ inventory_hostname }}:
              Current CURVINE_MASTER_HOSTNAME: {{ current_hostname.stdout | default('Not set') }}
              Should be set to: {{ node_ip }}
              {{ '✓ Correct' if current_hostname.stdout == node_ip else '⚠️ Incorrect, fixing...' }}

        - name: Remove old setting if incorrect
          lineinfile:
            path: /etc/profile
            regexp: '.*CURVINE_MASTER_HOSTNAME.*'
            state: absent
          when: current_hostname.stdout != node_ip

        - name: Add correct setting
          lineinfile:
            path: /etc/profile
            line: "export CURVINE_MASTER_HOSTNAME={{ node_ip }}"
            state: present
          when: current_hostname.stdout != node_ip

        - name: Source profile
          shell: source /etc/profile
          args:
            executable: /bin/bash
          when: current_hostname.stdout != node_ip
      when: "'master' in group_names"

    - name: Check and fix worker node environment
      block:
        - name: Display current status
          debug:
            msg: |
              Worker node {{ inventory_hostname }}:
              Current CURVINE_MASTER_HOSTNAME: {{ current_hostname.stdout | default('Not set') }}
              Should be set to: localhost
              {{ '✓ Correct' if current_hostname.stdout == 'localhost' else '⚠️ Incorrect, fixing...' }}

        - name: Remove old setting if incorrect
          lineinfile:
            path: /etc/profile
            regexp: '.*CURVINE_MASTER_HOSTNAME.*'
            state: absent
          when: current_hostname.stdout != 'localhost'

        - name: Add correct setting
          lineinfile:
            path: /etc/profile
            line: "export CURVINE_MASTER_HOSTNAME=localhost"
            state: present
          when: current_hostname.stdout != 'localhost'

        - name: Get current CURVINE_WORKER_HOSTNAME value
          shell: grep 'CURVINE_WORKER_HOSTNAME' /etc/profile | grep -v '^#' | tail -1 | sed 's/.*CURVINE_WORKER_HOSTNAME=//'
          register: current_worker_hostname
          ignore_errors: yes
          changed_when: false

        - name: Display worker hostname status
          debug:
            msg: |
              Worker node {{ inventory_hostname }}:
              Current CURVINE_WORKER_HOSTNAME: {{ current_worker_hostname.stdout | default('Not set') }}
              Should be set to: {{ inventory_hostname }}
              {{ '✓ Correct' if current_worker_hostname.stdout == inventory_hostname else '⚠️ Incorrect, fixing...' }}

        - name: Remove old CURVINE_WORKER_HOSTNAME setting if incorrect
          lineinfile:
            path: /etc/profile
            regexp: '.*CURVINE_WORKER_HOSTNAME.*'
            state: absent
          when: current_worker_hostname.stdout != inventory_hostname

        - name: Add correct CURVINE_WORKER_HOSTNAME setting
          lineinfile:
            path: /etc/profile
            line: "export CURVINE_WORKER_HOSTNAME={{ inventory_hostname }}"
            state: present
          when: current_worker_hostname.stdout != inventory_hostname

        - name: Source profile
          shell: source /etc/profile
          args:
            executable: /bin/bash
          when: current_hostname.stdout != 'localhost' or current_worker_hostname.stdout != inventory_hostname
      when: "'worker' in group_names"

- name: Start Curvine Master Services
  hosts: master
  gather_facts: no
  serial: 1
  any_errors_fatal: false
  ignore_unreachable: yes
  tasks:
    - name: Start curvine-master service
      systemd:
        name: curvine-master
        state: started
      register: master_start

    - name: Wait for master service to be ready
      wait_for:
        timeout: 10
      when: master_start.changed

    - name: Start curvine-worker service on master nodes
      systemd:
        name: curvine-worker
        state: started
      register: worker_start

    - name: Wait for worker service to be ready
      wait_for:
        timeout: 5
      when: worker_start.changed

    - name: Start curvine-fuse service on master nodes
      systemd:
        name: curvine-fuse
        state: started
      register: fuse_start

    - name: Check service status
      systemd:
        name: "{{ item }}"
      register: service_status
      loop:
        - curvine-master
        - curvine-worker
        - curvine-fuse

    - name: Display master node service status
      debug:
        msg: "Master node {{ inventory_hostname }} services started successfully"

- name: Start Curvine Worker Services
  hosts: worker
  gather_facts: no
  any_errors_fatal: false
  ignore_unreachable: yes
  vars:
    curvine_install_dir: /root/dist
  tasks:
    - name: Wait for master services to be fully ready
      wait_for:
        timeout: 5

    - name: Check if worker script exists
      stat:
        path: "{{ curvine_install_dir }}/bin/curvine-worker.sh"
      register: worker_script

    - name: Display worker script check
      debug:
        msg: "Worker startup script {{ 'exists' if worker_script.stat.exists else 'does not exist' }}: {{ curvine_install_dir }}/bin/curvine-worker.sh"

    - name: Fail if worker script does not exist
      fail:
        msg: |
          Worker startup script does not exist!
          Please check:
          1. Does dist1.tar.gz contain bin/curvine-worker.sh
          2. Was extraction successful
          3. Run diagnosis: ansible-playbook diagnose_worker.yml --limit {{ inventory_hostname }}
      when: not worker_script.stat.exists

    - name: Start curvine-worker service on worker nodes
      systemd:
        name: curvine-worker
        state: started
      register: worker_start
      ignore_errors: yes

    - name: Check worker service status if start failed
      shell: journalctl -u curvine-worker -n 20 --no-pager
      register: worker_logs
      when: worker_start.failed is defined and worker_start.failed

    - name: Display worker service error logs
      debug:
        msg: "Worker service startup failed, logs:\n{{ worker_logs.stdout }}"
      when: worker_start.failed is defined and worker_start.failed

    - name: Wait for worker service to be ready
      wait_for:
        timeout: 5
      when: worker_start.changed and not (worker_start.failed | default(false))

    - name: Start curvine-fuse service on worker nodes
      systemd:
        name: curvine-fuse
        state: started
      register: fuse_start
      ignore_errors: yes
      when: not (worker_start.failed | default(false))

    - name: Check fuse service status if start failed
      shell: journalctl -u curvine-fuse -n 20 --no-pager
      register: fuse_logs
      when: fuse_start.failed is defined and fuse_start.failed

    - name: Display fuse service error logs
      debug:
        msg: "FUSE service startup failed, logs:\n{{ fuse_logs.stdout }}"
      when: fuse_start.failed is defined and fuse_start.failed

    - name: Check service status
      systemd:
        name: "{{ item }}"
      register: service_status
      ignore_errors: yes
      loop:
        - curvine-worker
        - curvine-fuse

    - name: Display worker node service status
      debug:
        msg: |
          Worker node {{ inventory_hostname }}:
          - curvine-worker: {{ 'running' if not (worker_start.failed | default(false)) else 'failed' }}
          - curvine-fuse: {{ 'running' if not (fuse_start.failed | default(false)) else 'failed' }}

- name: Display cluster status
  hosts: localhost
  gather_facts: no
  tasks:
    - name: Success message
      debug:
        msg: |
          ========================================
          All Curvine cluster services started!
          
          To view detailed status run:
          ansible-playbook status_services.yml
          
          Access web interface at:
          http://<master-ip>:9000
          ========================================

