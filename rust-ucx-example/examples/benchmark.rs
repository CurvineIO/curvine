use anyhow::Result;
use log::info;
use std::time::{Duration, Instant};
use tokio::time::sleep;
use rust_ucx_example::{Context, ContextBuilder, Worker, WorkerBuilder};

use rust_ucx_example::{serialize_message, deserialize_message, Message, PerfStats};

/// UCXæ€§èƒ½åŸºå‡†æµ‹è¯•
/// æµ‹è¯•ä¸åŒæ¶ˆæ¯å¤§å°ä¸‹çš„å»¶è¿Ÿå’Œååé‡

const SERVER_PORT: u16 = 9998;
const WARMUP_ITERATIONS: u64 = 100;
const BENCHMARK_ITERATIONS: u64 = 1000;

// æµ‹è¯•ç”¨çš„ä¸åŒæ¶ˆæ¯å¤§å° (å­—èŠ‚)
const MESSAGE_SIZES: &[usize] = &[
    64,       // å°æ¶ˆæ¯
    512,      // ä¸­ç­‰æ¶ˆæ¯  
    1024,     // 1KB
    4096,     // 4KB
    16384,    // 16KB
    65536,    // 64KB
    262144,   // 256KB
    1048576,  // 1MB
];

#[derive(Debug)]
struct BenchmarkResult {
    message_size: usize,
    iterations: u64,
    total_time: Duration,
    avg_latency: Duration,
    min_latency: Duration,
    max_latency: Duration,
    throughput_mbps: f64,
    message_rate: f64,
}

async fn run_benchmark_server() -> Result<()> {
    info!("å¯åŠ¨æ€§èƒ½æµ‹è¯•æœåŠ¡å™¨");

    let mut context_builder = ContextBuilder::new();
    context_builder.request_tag_feature();
    let context = context_builder.build()?;
    let worker = WorkerBuilder::new(&context).build()?;

    let bind_addr = format!("127.0.0.1:{}", SERVER_PORT).parse()?;
    let listener = worker.create_listener(bind_addr).await?;
    info!("æœåŠ¡å™¨ç›‘å¬: {}", listener.socket_address()?);

    // ç­‰å¾…å®¢æˆ·ç«¯è¿æ¥
    let mut endpoint = None;
    while endpoint.is_none() {
        worker.progress();
        if let Some(conn_request) = listener.try_accept()? {
            endpoint = Some(conn_request.accept()?);
            info!("å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ");
        }
        sleep(Duration::from_millis(10)).await;
    }
    
    let endpoint = endpoint.unwrap();
    let mut buffer = vec![0u8; 2 * 1024 * 1024]; // 2MBç¼“å†²åŒº
    let mut total_messages = 0u64;

    info!("å¼€å§‹å¤„ç†åŸºå‡†æµ‹è¯•æ¶ˆæ¯...");
    
    loop {
        worker.progress();
        
        if let Some(received) = endpoint.try_receive_tag(0, &mut buffer)? {
            let data = &buffer[..received];
            
            match deserialize_message(data) {
                Ok(Message::Ping { seq, data: ping_data }) => {
                    total_messages += 1;
                    
                    // ç«‹å³å›å¤pong
                    let pong = Message::Pong { seq };
                    let pong_data = serialize_message(&pong)?;
                    endpoint.send_tag(0, &pong_data)?;
                    
                    if total_messages % 1000 == 0 {
                        info!("å·²å¤„ç† {} æ¡æ¶ˆæ¯", total_messages);
                    }
                }
                Ok(Message::Disconnect) => {
                    info!("æ”¶åˆ°æ–­å¼€è¿æ¥ï¼Œæ€»è®¡å¤„ç† {} æ¡æ¶ˆæ¯", total_messages);
                    break;
                }
                Ok(_) => {
                    // å¿½ç•¥å…¶ä»–æ¶ˆæ¯ç±»å‹
                }
                Err(e) => {
                    log::warn!("è§£ææ¶ˆæ¯å¤±è´¥: {}", e);
                }
            }
        }
        
        sleep(Duration::from_nanos(100)).await; // å‡å°‘CPUä½¿ç”¨
    }

    info!("æ€§èƒ½æµ‹è¯•æœåŠ¡å™¨é€€å‡º");
    Ok(())
}

async fn run_benchmark_client() -> Result<()> {
    info!("å¯åŠ¨æ€§èƒ½æµ‹è¯•å®¢æˆ·ç«¯");
    
    // ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
    sleep(Duration::from_millis(1000)).await;

    let mut context_builder = ContextBuilder::new();
    context_builder.request_tag_feature();
    let context = context_builder.build()?;
    let worker = WorkerBuilder::new(&context).build()?;

    let server_addr = format!("127.0.0.1:{}", SERVER_PORT).parse()?;
    let endpoint = worker.connect(server_addr).await?;
    info!("è¿æ¥åˆ°æœåŠ¡å™¨: {}", server_addr);

    // ç­‰å¾…è¿æ¥ç¨³å®š
    sleep(Duration::from_millis(200)).await;

    let mut buffer = vec![0u8; 2 * 1024 * 1024]; // 2MBç¼“å†²åŒº
    let mut results = Vec::new();

    for &message_size in MESSAGE_SIZES {
        info!("å¼€å§‹æµ‹è¯•æ¶ˆæ¯å¤§å°: {} bytes", message_size);
        
        // é¢„çƒ­é˜¶æ®µ
        info!("é¢„çƒ­é˜¶æ®µ: {} æ¬¡è¿­ä»£", WARMUP_ITERATIONS);
        for seq in 0..WARMUP_ITERATIONS {
            let ping_data = vec![42u8; message_size];
            let ping = Message::Ping { seq, data: ping_data };
            
            let ping_msg = serialize_message(&ping)?;
            endpoint.send_tag(0, &ping_msg)?;
            worker.progress();
            
            // ç­‰å¾…å“åº”
            let mut received_response = false;
            let timeout = Duration::from_millis(1000);
            let start = Instant::now();
            
            while start.elapsed() < timeout && !received_response {
                worker.progress();
                
                if let Some(received) = endpoint.try_receive_tag(0, &mut buffer)? {
                    if let Ok(Message::Pong { .. }) = deserialize_message(&buffer[..received]) {
                        received_response = true;
                    }
                }
                
                if !received_response {
                    sleep(Duration::from_nanos(100)).await;
                }
            }
        }
        
        info!("é¢„çƒ­å®Œæˆï¼Œå¼€å§‹æ­£å¼æµ‹è¯•: {} æ¬¡è¿­ä»£", BENCHMARK_ITERATIONS);
        
        // æ­£å¼æµ‹è¯•é˜¶æ®µ
        let mut latencies = Vec::with_capacity(BENCHMARK_ITERATIONS as usize);
        let test_start = Instant::now();
        
        for seq in 0..BENCHMARK_ITERATIONS {
            let ping_data = vec![42u8; message_size];
            let ping = Message::Ping { seq, data: ping_data };
            
            let request_start = Instant::now();
            
            // å‘é€ping
            let ping_msg = serialize_message(&ping)?;
            endpoint.send_tag(0, &ping_msg)?;
            worker.progress();
            
            // ç­‰å¾…pongå“åº”
            let mut received_response = false;
            let timeout = Duration::from_millis(5000);
            let response_start = Instant::now();
            
            while response_start.elapsed() < timeout && !received_response {
                worker.progress();
                
                if let Some(received) = endpoint.try_receive_tag(0, &mut buffer)? {
                    if let Ok(Message::Pong { seq: pong_seq }) = deserialize_message(&buffer[..received]) {
                        if pong_seq == seq {
                            let latency = request_start.elapsed();
                            latencies.push(latency);
                            received_response = true;
                        }
                    }
                }
                
                if !received_response {
                    sleep(Duration::from_nanos(100)).await;
                }
            }
            
            if !received_response {
                log::warn!("åºåˆ—å· {} è¶…æ—¶", seq);
            }
            
            // æ‰“å°è¿›åº¦
            if seq % (BENCHMARK_ITERATIONS / 10) == 0 && seq > 0 {
                info!("è¿›åº¦: {}/{}", seq, BENCHMARK_ITERATIONS);
            }
        }
        
        let total_time = test_start.elapsed();
        
        // è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if !latencies.is_empty() {
            let avg_latency = latencies.iter().sum::<Duration>() / latencies.len() as u32;
            let min_latency = *latencies.iter().min().unwrap();
            let max_latency = *latencies.iter().max().unwrap();
            
            let total_bytes = (message_size * latencies.len() * 2) as f64; // åŒå‘ä¼ è¾“
            let throughput_mbps = (total_bytes / (1024.0 * 1024.0)) / total_time.as_secs_f64();
            let message_rate = latencies.len() as f64 / total_time.as_secs_f64();
            
            let result = BenchmarkResult {
                message_size,
                iterations: latencies.len() as u64,
                total_time,
                avg_latency,
                min_latency,
                max_latency,
                throughput_mbps,
                message_rate,
            };
            
            results.push(result);
            
            info!("æ¶ˆæ¯å¤§å° {} bytes æµ‹è¯•å®Œæˆ:", message_size);
            info!("  æˆåŠŸè¿­ä»£: {}/{}", latencies.len(), BENCHMARK_ITERATIONS);
            info!("  å¹³å‡å»¶è¿Ÿ: {:?}", avg_latency);
            info!("  æœ€å°å»¶è¿Ÿ: {:?}", min_latency);
            info!("  æœ€å¤§å»¶è¿Ÿ: {:?}", max_latency);
            info!("  ååé‡: {:.2} MB/s", throughput_mbps);
            info!("  æ¶ˆæ¯é€Ÿç‡: {:.2} msg/s", message_rate);
        }
        
        // æµ‹è¯•é—´éš”
        sleep(Duration::from_millis(500)).await;
    }

    // å‘é€æ–­å¼€è¿æ¥æ¶ˆæ¯
    let disconnect = Message::Disconnect;
    let disconnect_msg = serialize_message(&disconnect)?;
    endpoint.send_tag(0, &disconnect_msg)?;
    worker.progress();

    // æ‰“å°æ±‡æ€»ç»“æœ
    print_benchmark_summary(&results);

    info!("æ€§èƒ½æµ‹è¯•å®¢æˆ·ç«¯é€€å‡º");
    Ok(())
}

fn print_benchmark_summary(results: &[BenchmarkResult]) {
    println!("\n=== UCX æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ ===");
    println!();
    println!("{:>10} {:>12} {:>12} {:>12} {:>12} {:>12} {:>15}",
             "æ¶ˆæ¯å¤§å°", "è¿­ä»£æ¬¡æ•°", "å¹³å‡å»¶è¿Ÿ", "æœ€å°å»¶è¿Ÿ", "æœ€å¤§å»¶è¿Ÿ", "ååé‡", "æ¶ˆæ¯é€Ÿç‡");
    println!("{:>10} {:>12} {:>12} {:>12} {:>12} {:>12} {:>15}",
             "(bytes)", "(æ¬¡)", "(Î¼s)", "(Î¼s)", "(Î¼s)", "(MB/s)", "(msg/s)");
    println!("{:-<10} {:-<12} {:-<12} {:-<12} {:-<12} {:-<12} {:-<15}",
             "", "", "", "", "", "", "");

    for result in results {
        println!("{:>10} {:>12} {:>12.1} {:>12.1} {:>12.1} {:>12.2} {:>15.0}",
                 result.message_size,
                 result.iterations,
                 result.avg_latency.as_micros() as f64,
                 result.min_latency.as_micros() as f64,
                 result.max_latency.as_micros() as f64,
                 result.throughput_mbps,
                 result.message_rate);
    }
    
    println!();
    
    // æ‰¾å‡ºæœ€ä½³æ€§èƒ½ç‚¹
    if let Some(best_latency) = results.iter().min_by_key(|r| r.avg_latency) {
        println!("ğŸš€ æœ€ä½å»¶è¿Ÿ: {} bytes @ {:.1} Î¼s", 
                 best_latency.message_size, 
                 best_latency.avg_latency.as_micros() as f64);
    }
    
    if let Some(best_throughput) = results.iter().max_by(|a, b| a.throughput_mbps.partial_cmp(&b.throughput_mbps).unwrap()) {
        println!("ğŸ”¥ æœ€é«˜ååé‡: {} bytes @ {:.2} MB/s", 
                 best_throughput.message_size, 
                 best_throughput.throughput_mbps);
    }
    
    if let Some(best_rate) = results.iter().max_by(|a, b| a.message_rate.partial_cmp(&b.message_rate).unwrap()) {
        println!("âš¡ æœ€é«˜æ¶ˆæ¯é€Ÿç‡: {} bytes @ {:.0} msg/s", 
                 best_rate.message_size, 
                 best_rate.message_rate);
    }
    
    println!();
}

#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    env_logger::Builder::from_env(
        env_logger::Env::default().default_filter_or("info")
    ).init();

    println!("=== UCX æ€§èƒ½åŸºå‡†æµ‹è¯• ===");
    println!("æµ‹è¯•é…ç½®:");
    println!("  é¢„çƒ­è¿­ä»£: {}", WARMUP_ITERATIONS);
    println!("  æµ‹è¯•è¿­ä»£: {}", BENCHMARK_ITERATIONS);
    println!("  æ¶ˆæ¯å¤§å°: {:?} bytes", MESSAGE_SIZES);
    println!();

    // å¹¶å‘è¿è¡ŒæœåŠ¡å™¨å’Œå®¢æˆ·ç«¯
    let server_handle = tokio::spawn(run_benchmark_server());
    let client_handle = tokio::spawn(run_benchmark_client());

    // ç­‰å¾…å®¢æˆ·ç«¯å®Œæˆï¼Œç„¶åç­‰å¾…æœåŠ¡å™¨
    match client_handle.await {
        Ok(Ok(())) => info!("å®¢æˆ·ç«¯æµ‹è¯•å®Œæˆ"),
        Ok(Err(e)) => log::error!("å®¢æˆ·ç«¯å‡ºé”™: {}", e),
        Err(e) => log::error!("å®¢æˆ·ç«¯ä»»åŠ¡å¤±è´¥: {}", e),
    }

    // ç»™æœåŠ¡å™¨ä¸€ç‚¹æ—¶é—´æ¸…ç†
    sleep(Duration::from_millis(500)).await;

    match server_handle.await {
        Ok(Ok(())) => info!("æœåŠ¡å™¨æ­£å¸¸é€€å‡º"),
        Ok(Err(e)) => log::error!("æœåŠ¡å™¨å‡ºé”™: {}", e),
        Err(e) => log::error!("æœåŠ¡å™¨ä»»åŠ¡å¤±è´¥: {}", e),
    }

    println!("åŸºå‡†æµ‹è¯•å®Œæˆï¼");
    Ok(())
}
